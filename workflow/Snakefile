import os
import sys
import math
from snakemake.utils import min_version

min_version("6.0")

SDIR = os.path.realpath(os.path.dirname(srcdir("Snakefile")))
shell.prefix(f"set -eo pipefail; ")


configfile: "config/config.yaml"


config["temp"] = config.get("temp", "temp")
config["tech"] = config.get("tech", "nanopore-raw")
config["threads"] = config.get("threads", 40)
config["genomeSize"] = config.get("genomeSize", "3g")
config["github"] = config.get("github", "")
print(config)


wildcard_constraints:
    pre=config["prefix"],
    hap="mat|pat|reads",


rule collect_reads:
    input:
        reads=lambda wc: config[wc.hap],
    output:
        fasta="{temp}/{pre}.{hap}.fasta",
    conda:
        "envs/env.yaml"
    threads: 8
    shell:
        """
        if [[ {input.reads} =~ .*\.(fofn) ]]; then
                cat $(cat {input.reads}) | seqtk seq -l 80 -A > {output.fasta}
        elif [[ {input.reads} =~ .*\.(fa|fq|fasta|fastq|gz) ]]; then
                cat {input.reads} | seqtk seq -l 80 -A > {output.fasta}
        elif [[ {input.reads} =~ .*\.(bam|sam|cram) ]]; then
                samtools fasta -@ {threads} -o {output.fasta} {input.reads}
        fi
        """


#
# Hifiasm
#
rule yak:
    input:
        reads="{temp}/{pre}.{hap}.fasta",
    output:
        yak="{temp}/{pre}.{hap}.fasta.yak",
    threads: 30
    conda:
        "envs/env.yaml"
    shell:
        """
        yak count -k31 -b37 -t {threads} -o {output.yak} {input.reads}
        """


rule trio_hifiasm:
    input:
        pat=expand(rules.yak.output.yak, hap="pat", allow_missing=True),
        mat=expand(rules.yak.output.yak, hap="mat", allow_missing=True),
        reads=expand(rules.collect_reads.output, hap="reads", allow_missing=True),
    output:
        hap1="{temp}/{pre}.dip.hap1.p_ctg.gfa",
        hap2="{temp}/{pre}.dip.hap2.p_ctg.gfa",
        hap1fa="{temp}/{pre}.hap1.fa",
        hap2fa="{temp}/{pre}.hap2.fa",
    threads: 80
    conda:
        "envs/env.yaml"
    shell:
        """
        hifiasm -o {wildcards.temp}/{wildcards.pre} -t {threads} \
            -1 {input.pat} -2 {input.mat} {input.reads} 

        awk '/^S/{{print ">"$2"_hap1\\n"$3}}' {output.hap1} \
            | seqtk seq -l 80 > {output.hap1fa}

        awk '/^S/{{print ">"$2"_hap2\\n"$3}}' {output.hap2} \
            | seqtk seq -l 80 > {output.hap2fa}
        """


rule hifiasm:
    input:
        expand(rules.trio_hifiasm.output, pre=config["prefix"], temp=config["temp"]),


#
# Hicanu
#
rule run_trio_binning:
    input:
        fasta=expand(
            rules.collect_reads.output.fasta,
            temp=config["temp"],
            hap="reads",
            pre=config["prefix"],
        ),
        mat=expand(
            rules.collect_reads.output.fasta,
            temp=config["temp"],
            hap="mat",
            pre=config["prefix"],
        ),
        pat=expand(
            rules.collect_reads.output.fasta,
            temp=config["temp"],
            hap="pat",
            pre=config["prefix"],
        ),
    output:
        mat=expand(
            "{temp}/{pre}/haplotype/haplotype-mat.fasta.gz",
            temp=config["temp"],
            pre=config["prefix"],
        ),
        pat=expand(
            "{temp}/{pre}/haplotype/haplotype-pat.fasta.gz",
            temp=config["temp"],
            pre=config["prefix"],
        ),
        unk=expand(
            "{temp}/{pre}/haplotype/haplotype-unknown.fasta.gz",
            temp=config["temp"],
            pre=config["prefix"],
        ),
        trio=temp(directory(config["temp"] + "/" + config["prefix"])),
    params:
        tech=config["tech"],
        tmp=config["temp"],
        genomeSize=config["genomeSize"],
        github_opt=config["github"],
    conda:
        "envs/env.yaml"
    threads: config["threads"]
    shell:
        """
        which canu
        canu --version
        canu -haplotype \
            {params.github_opt} \
            maxThreads={threads} \
            useGrid=false \
            -p asm -d {output.trio} \
            -genomeSize={params.genomeSize} \
            -haplotypemat {input.mat} \
            -haplotypepat {input.pat} \
            -{params.tech} {input.fasta}
        """


rule run_hicanu:
    input:
        reads="{temp}/{pre}/haplotype/haplotype-{hap}.fasta.gz",
    output:
        canu_dir=directory("{temp}/{pre}/{hap}/"),
        fasta="{temp}/{pre}/{hap}/{pre}_{hap}.contigs.fasta",
    params:
        genomeSize=config["genomeSize"],
        github_opt=config["github"],
    conda:
        "envs/env.yaml"
    threads: config["threads"]
    shell:
        """
        canu \
            {params.github_opt} \
            maxThreads={threads} \
            useGrid=false \
            -p {wildcards.pre}_{wildcards.hap} \
            -d {output.canu_dir} \
            -genomeSize={params.genomeSize} \
            -pacbio-hifi {input.reads}
        """


rule hicanu:
    input:
        expand(
            rules.run_hicanu.output,
            pre=config["prefix"],
            temp=config["temp"],
            hap=["mat", "pat"],
        ),


#
# Stats
#
rule move_reads:
    input:
        mat=rules.run_trio_binning.output.mat,
        pat=rules.run_trio_binning.output.pat,
        unk=rules.run_trio_binning.output.unk,
        trio=rules.run_trio_binning.output.trio,
    output:
        mat="results/{pre}/mat.fa.gz",
        pat="results/{pre}/pat.fa.gz",
        unk="results/{pre}/unk.fa.gz",
    conda:
        "envs/env.yaml"
    shell:
        """
        cp {input.mat} {output.mat}
        cp {input.pat} {output.pat}
        cp {input.unk} {output.unk}
        """


rule read_stats:
    input:
        mat=rules.run_trio_binning.output.mat,
        pat=rules.run_trio_binning.output.pat,
        unk=rules.run_trio_binning.output.unk,
    output:
        tbl="results/{pre}/phasing.stats.tbl",
    conda:
        "envs/env.yaml"
    threads: 1
    shell:
        "{SDIR}/scripts/phasing_by_lengths.py {input} > {output}"


rule all:
    input:
        expand(rules.move_reads.output, pre=config["prefix"]),
        expand(rules.read_stats.output, pre=config["prefix"]),
        expand(rules.run_trio_binning.output.trio, pre=config["prefix"]),
